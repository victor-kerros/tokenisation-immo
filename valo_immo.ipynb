{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660234b5",
   "metadata": {},
   "source": [
    "# *Projet Python ENSAE*\n",
    "\n",
    "## Tokenisation d'actifs immobiliers - partie valorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4b487",
   "metadata": {},
   "source": [
    "Le but de ce notebook principal est de **créer un modèle de valorisation des actifs immobiliers**. Pour cela, nous utilisons principalement les données extraites du **dataset Demande de Valeurs Foncières** (DVF) et des **données INSEE**. Nous nous sommes inspirés d'un projet d'Arnaud Hureaux que nous avons cherché ) approfondir et compléter.\n",
    "\n",
    "Lien projet (source d'inspiration) : https://hureauxarnaud.medium.com/projet-estimateur-de-prix-dun-bien-immobilier-bas%C3%A9-sur-du-machine-learning-ae578fdacaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d264493",
   "metadata": {},
   "source": [
    "# Plan du notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d727ef",
   "metadata": {},
   "source": [
    "**Etape 0 : packages et importations de données**\n",
    "\n",
    "**Etape 1 : preprocessing**\n",
    "\n",
    "* 1.1. Importation du dataset DVF\n",
    "* 1.2. Visualisation des données DVF\n",
    "* 1.3. Création du dataset final DVF\n",
    "* 1.4. Valeurs extrêmes dans le dataset DVF\n",
    "\n",
    "**Etape 2 : feature engineering**\n",
    "\n",
    "* 2.1. Choix des nouveaux features\n",
    "* 2.2. Importation des nouveaux features\n",
    "* 2.3. Jointure des deux bases de données\n",
    "\n",
    "**Etape 3 : analyse descriptive**\n",
    "\n",
    "* 3.1. Premières analyses\n",
    "* 3.2. Analyse de la répartition des prix de vente\n",
    "* 3.3. Analyse de la corrélation entre surface et prix de vente\n",
    "* 3.4. Premières intuitions sur l'analyse à l'échelle d'un département\n",
    "\n",
    "**Etape 4 : modélisation**\n",
    "\n",
    "* 4.1. Métriques et variables \"dummies\"\n",
    "* 4.2. Modélisation sur tous les départements\n",
    "* 4.3. Restriction au 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154eea4",
   "metadata": {},
   "source": [
    "# Etape 0 : packages et importations de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38547454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.9/site-packages (0.13.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.7.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25->statsmodels) (2021.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.9/site-packages (0.10.2)\n",
      "Requirement already satisfied: fiona>=1.8 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.20)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from geopandas) (3.3.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.3.4)\n",
      "Requirement already satisfied: shapely>=1.6 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.0)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (58.5.3)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (8.0.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas) (1.20.3)\n",
      "Requirement already satisfied: folium in /opt/conda/lib/python3.9/site-packages (0.12.1.post1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from folium) (1.20.3)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.9/site-packages (from folium) (3.0.3)\n",
      "Requirement already satisfied: branca>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from folium) (2.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2>=2.9->folium) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->folium) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->folium) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->folium) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->folium) (3.1)\n"
     ]
    }
   ],
   "source": [
    "# Importation des packages importants\n",
    "\n",
    "!pip install nltk\n",
    "!pip install unidecode\n",
    "!pip install statsmodels\n",
    "!pip install geopandas\n",
    "!pip install folium\n",
    "\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "import unidecode\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd541ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in /opt/conda/lib/python3.9/site-packages (0.1.3)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'retrieve_data' from 'external_data' (external_data.ipynb)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_225/3237383295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install import-ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexternal_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mretrieve_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'retrieve_data' from 'external_data' (external_data.ipynb)"
     ]
    }
   ],
   "source": [
    "# Importation de données externes traitées dans un autre fichier\n",
    "# Voire partie 2 (features) & le notebook external_data\n",
    "!pip install import-ipynb\n",
    "import import_ipynb\n",
    "from external_data import retrieve_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97025158",
   "metadata": {},
   "source": [
    "# Etape 1 : preprocessing DVF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2c34c-fc10-4be2-b04e-961ad0f01601",
   "metadata": {},
   "source": [
    "### 1.1. Importation du dataset DVF :\n",
    "\n",
    "Nous importons le dataset « **Demandes de valeurs foncières** » (DVF), publié par la DGFiP, permet de connaître les transactions immobilières intervenues au cours des cinq dernières années sur le territoire métropolitain et les DOM-TOM, à l’exception de l’Alsace, de la Moselle et de Mayotte. Les données contenues sont issues des actes notariés et des informations cadastrales.\n",
    "\n",
    "Fichiers 2017-2020 : https://files.data.gouv.fr/geo-dvf/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "04c30121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\leo\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from geopandas) (3.2.1)\n",
      "Requirement already satisfied: shapely>=1.6 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from geopandas) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from geopandas) (1.2.4)\n",
      "Requirement already satisfied: fiona>=1.8 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from geopandas) (1.8.20)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (52.0.0.post20210125)\n",
      "Requirement already satisfied: gdal~=3.3.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (3.3.3)\n",
      "Requirement already satisfied: munch in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (2021.5.30)\n",
      "Requirement already satisfied: six>=1.7 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: attrs>=17 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->geopandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->geopandas) (1.19.2)\n",
      "Requirement already satisfied: folium in c:\\users\\leo\\anaconda3\\lib\\site-packages (0.12.1.post1)\n",
      "Requirement already satisfied: numpy in c:\\users\\leo\\anaconda3\\lib\\site-packages (from folium) (1.19.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from folium) (2.11.3)\n",
      "Requirement already satisfied: branca>=0.3.0 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\leo\\anaconda3\\lib\\site-packages (from folium) (2.25.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from requests->folium) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from requests->folium) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from requests->folium) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leo\\anaconda3\\lib\\site-packages (from requests->folium) (1.26.4)\n",
      "Requirement already satisfied: import-ipynb in c:\\users\\leo\\anaconda3\\lib\\site-packages (0.1.3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-7fdddd011b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://files.data.gouv.fr/geo-dvf/latest/csv/2021/full.csv.gz\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# On ne travaille que sur les données du S1 2021, afin d'avoir des calculs moins coûteux en temps.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m     \"\"\"\n\u001b[0;32m    539\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Les fichiers sont issus de https://files.data.gouv.fr/geo-dvf/latest/\n",
    "\n",
    "name = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2021/full.csv.gz\"\n",
    "table = pd.read_csv(name, sep = ',')\n",
    "\n",
    "# On ne travaille que sur les données du S1 2021, afin d'avoir des calculs moins coûteux en temps.\n",
    "# Les transactions du S1 2021 représentent tout de même un dataset de 1 200 000 lignes...\n",
    "# Pour travailler sur l'ensemble des données (2017-2021), il suffit d'enlever les guillemets ci-dessous.\n",
    "\n",
    "\"\"\"\n",
    "for year in range(2017, 2021):\n",
    "    name = \"https://files.data.gouv.fr/geo-dvf/latest/csv/\" + str(year) + \"/full.csv.gz\"\n",
    "    table = pd.concat([table, pd.read_csv(name, sep = ',')])\n",
    "\n",
    "display(\"Taille de table :\")\n",
    "display(table.shape)\n",
    "table.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f9ecc-fbac-477f-a3d0-fdc27d14e487",
   "metadata": {},
   "source": [
    "### 1.2. Visualisation des données DVF\n",
    "\n",
    "Il s'agit dans cette section de se faire **des premières intuitions sur les données**. \n",
    "\n",
    "En particulier, on se rend compte d'un **problème de preprocessing** : une transaction peut correspondre à plusieurs lignes avec la même valeur foncière sur chaque ligne. Autrement dit, **DVF affiche le même prix de vente global à chaque lot d'une même transaction**.\n",
    "\n",
    "Pour observer cela, nous allons créer **un identifiant de transaction unique**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eed53c-65bf-4b6a-b351-b24daf16a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une adresse générique\n",
    "\n",
    "table['adresse_numero'] = table['adresse_numero'].fillna('0').astype(int)\n",
    "table['adresse_suffixe'] = table['adresse_suffixe'].fillna(' ')\n",
    "table['adresse_code_voie'] = table['adresse_code_voie'].fillna(' ')\n",
    "table['adresse_nom_voie'] = table['adresse_nom_voie'].fillna(' ')\n",
    "table['code_postal'] = table['code_postal'].fillna('0').astype(int)\n",
    "table['nom_commune'] = table['nom_commune'].fillna(' ')\n",
    "\n",
    "#Ajout de \"\\\" pour que l'opération soit visible à l'écran en entier\n",
    "table[\"adresse\"] = table['adresse_numero'].astype(str) + ' ' + table['adresse_suffixe'] + ' ' + \\\n",
    "                table['adresse_code_voie'] + ' ' + table['adresse_nom_voie'] + ' ' + table['nom_commune'] + ' ' + \\\n",
    "                table['code_postal'].astype(str) + ' ' + 'France'\n",
    "\n",
    "# Création d'un identifiant de transaction\n",
    "\n",
    "# Pour identifier les doublons, l'adresse ne suffit pas : un bien peut avoir été vendu deux fois dans la même année\n",
    "table[\"identifiant_transaction\"] = table[\"adresse\"].astype(str) + ' le ' + table[\"date_mutation\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702dec8-b3f1-4549-ad94-74c6d32bd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problème dans les données et vérification de la validité de l'identifiant de transaction :\n",
    "\n",
    "display(table[\"identifiant_transaction\"].loc[0])\n",
    "display(table[\"identifiant_transaction\"].loc[1])\n",
    "display(\"Si l'identifiant de transaction est valide, alors True doit s'afficher :\")\n",
    "table[\"identifiant_transaction\"].loc[0] == table[\"identifiant_transaction\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1bce8-c53a-4f1c-8e08-4917df218b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On constate, encore une fois, le problème relevé ci-dessus :\n",
    "\n",
    "display(\"Nombre d'adresses uniques dans le DataFrame :\")\n",
    "display(len(table[\"adresse\"].unique()))\n",
    "\n",
    "display(\"Nombre d'identifiant_transaction uniques dans le DataFrame :\")\n",
    "display(len(table[\"identifiant_transaction\"].unique()))\n",
    "\n",
    "display(\"Nombre de lignes dans le DataFrame :\")\n",
    "display(len(table))\n",
    "\n",
    "display(\"Nombre moyen de lignes par vente :\")\n",
    "np.round(len(table) / len(table[\"identifiant_transaction\"].unique()), 2)\n",
    "\n",
    "# Une vente correspond à plusieurs lignes, les informations sont donc diffusées dans ces lignes..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7b701-c0b7-4d04-b3cd-b547123681c9",
   "metadata": {},
   "source": [
    "Dès lors, si on entraîne l'algorithme de pricing sur ce dataset, il sera **biaisé** : \n",
    "* d'une part, il associerait à une dépendance de 20 m2 le prix d'un appartement de 200 m2\n",
    "* d'autre part, il ne prendrait pas en compte la plus-value apportée par un jardin à une maison, par une dépendance à un appartement, etc.\n",
    "\n",
    "Il conviendra donc de **retravailler les données pour obtenir une seule ligne par transaction**.\n",
    "\n",
    "**Le notebook \"cleaning-dvf\"** (lien : https://github.com/victor-kerros/tokenisation-immo/blob/main/cleaning-dvf.ipynb) revient en détail sur ce problème de preprocessing et effectue ce travail de nettoyage. Dans la mesure où cette solution de nettoyage est très coûteuse en temps, nous privilégions **une solution plus efficace** dans le cadre de ce projet : nous ne retenons que les transactions ne faisant l'objet que d'une seule ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73870b-6be9-46a3-8851-e3e92655159a",
   "metadata": {},
   "source": [
    "### 1.3. Création du dataset final DVF\n",
    "\n",
    "D'abord, nous ne prenons que les colonnes suivantes :\n",
    "- Date de vente/mutation\n",
    "- Nature mutation (pour séparer les ventes en VEFA et les ventes classiques)\n",
    "- Valeur foncière (prix de vente)\n",
    "- Colonnes liées à l’adresse (pour nous permettre de localiser le bien)\n",
    "- Adresse\n",
    "- Code Postal\n",
    "- Type local (maison/appartement/Local commercial/Dépendance etc)\n",
    "- Surface réelle bâtie (nb de mètre carré du bien bâti)\n",
    "- Surface terrain (nb de mètre carré du terrain associé au bien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée le dataframe table_vf avec les seules colonnes qui nous intéressent\n",
    "colonnes = [\"date_mutation\", \"nature_mutation\", \"valeur_fonciere\", \"code_postal\", 'type_local',\n",
    "            'surface_reelle_bati', 'nombre_pieces_principales', 'nature_culture', 'surface_terrain', 'longitude', \n",
    "            'latitude', 'adresse', 'code_departement', 'identifiant_transaction']\n",
    "table_vf = table[colonnes].copy()\n",
    "\n",
    "# On agrège les types de cultures différents de NaN, sols, terrain à bâtir et  : on les renomme \"culture\"\n",
    "culture_type = ['taillis simples', 'eaux', 'landes', 'taillis sous futaie', 'prés', 'terres', 'peupleraies', \n",
    "                'vignes', 'bois', 'vergers', 'carrières', 'futaies résineuses', 'pâtures', 'futaies feuillues', \n",
    "                'futaies mixtes', 'chemin de fer', 'oseraies', 'pacages', 'prés plantes', 'terres plantées', \n",
    "                'landes boisées', 'herbages', \"prés d'embouche\"]\n",
    "\n",
    "for x in culture_type:\n",
    "    table_vf.loc[table_vf[\"nature_culture\"] == x, \"nature_culture\"] = \"culture\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00850d89-73de-492a-ba82-d5f2db37654d",
   "metadata": {},
   "source": [
    "Ensuite, comme annoncé, nous ne retenons que les transactions ne faisant l'objet que d'une seule ligne pour créer \"data\" : le dataset final avec lequel nous allons travailler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de55892-9598-4345-b163-690c49816e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne retient que les transactions ayant fait l'objet d'une seule et unique ligne\n",
    "table_vf_dup = table_vf.copy()\n",
    "table_vf_uni = table_vf.copy()\n",
    "\n",
    "# On récupère les indices des transactions dupliquées...\n",
    "# i.e. les lignes où on retrouve un id de transaction utilisé ailleurs\n",
    "dup_id = table_vf_dup.groupby('identifiant_transaction').size()\n",
    "dup_id = dup_id[dup_id > 1]\n",
    "dup_id = dup_id.reset_index()\n",
    "\n",
    "table_vf_dup = table_vf_dup[table_vf_dup['identifiant_transaction'].isin(dup_id[\"identifiant_transaction\"])]\n",
    "table_vf_uni = table_vf_uni[~table_vf_uni['identifiant_transaction'].isin(dup_id[\"identifiant_transaction\"])]\n",
    "\n",
    "print(\"Taille de table_vf_uni (nombre de transactions non dupliquées) :\")\n",
    "print(table_vf_uni.shape)\n",
    "\n",
    "# La solution la plus efficace, pour éviter un nettoyage trop coûteux en temps...\n",
    "# est de ne retenir que les transactions non dupliquées.\n",
    "data = table_vf_uni\n",
    "data = data.reset_index().drop(\"index\", axis = 1)\n",
    "\n",
    "# Visualisation de data\n",
    "display(\"Les trois premières lignes de data :\")\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8392b-b333-42d7-8b4c-fce911f06fe1",
   "metadata": {},
   "source": [
    "### 1.4. Valeurs extrêmes dans le dataset DVF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782a8a7-09e7-428b-91f9-6d95638096fb",
   "metadata": {},
   "source": [
    "On s'intéresse aux **valeurs extrêmes dans le dataset**. En effet, afin d'avoir un entraînement fiable, nous devons les enlever (sinon, il y aura trop de bruit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a3101-6bda-49eb-8f59-51b4f1765436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_display(data):\n",
    "\n",
    "    fig, axs = plt.subplots(1,4)\n",
    "    fig.suptitle(\"Boxplot des variables d'intérêt :\")\n",
    "\n",
    "    axs[0].boxplot(data[data['valeur_fonciere'].notna()]['valeur_fonciere'])\n",
    "    axs[0].set(title = \"Valeurs foncières\")\n",
    "\n",
    "    axs[1].boxplot(data[data['surface_reelle_bati'].notna()]['surface_reelle_bati'])\n",
    "    axs[1].set(title = \"Surface bati\")\n",
    "\n",
    "    axs[2].boxplot(data[data['nombre_pieces_principales'].notna()]['nombre_pieces_principales'])\n",
    "    axs[2].set(title = \"Nbre pièces\")\n",
    "\n",
    "    axs[3].boxplot(data[data['surface_terrain'].notna()]['surface_terrain'])\n",
    "    axs[3].set(title = \"Surface terrain\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9ce00-34e1-475c-ab50-3673db85eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f373e6-e8e9-414b-aa97-9432c98dd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"valeur_fonciere\", y = \"type_local\", data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503a9d-089f-4bcf-bf8e-b21e9d7d551a",
   "metadata": {},
   "source": [
    "On constate sur ces boxplots que le dataset présente des valeurs extrêmes **particulièrement hautes** dans les quatre variables d'intérêt. \n",
    "\n",
    "En particulier, les locaux industriels, commerciaux et assimilés ont des valeurs extrêmes très importantes.\n",
    "\n",
    "On observe également des valeurs extrêmes **particulièrement basses**, comme le montrent les cellules ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00617e15-8b29-412c-a50d-16b43208a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(data[\"valeur_fonciere\"]))\n",
    "valeurs = [1.0, 10.0, 1000.0, 5000.0, 10000.0]\n",
    "for i in valeurs:\n",
    "    display(\"Le nombre de valeurs foncières inférieures ou égales à \"+str(i)+\" est de:\")\n",
    "    display(sum(data[\"valeur_fonciere\"] <= i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a201e-ebf0-4dff-9fef-2ec7390ba0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(data[\"surface_reelle_bati\"]))\n",
    "valeurs = [1.0, 5.0, 10.0, 30.0]\n",
    "for i in valeurs:\n",
    "    display(\"Le nombre de surfaces bati intérieures ou égales à \"+str(i)+\" est de:\")\n",
    "    display(sum(data[\"surface_reelle_bati\"] <= i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef9340-eeac-477a-a9ad-04e5b69e4628",
   "metadata": {},
   "source": [
    "On constate que bien qu'il n'y ait pas de valeurs foncières nulle, il y en a **de nombreuses qui sont inférieures ou égales à 10**.\n",
    "On considère qu'**une transaction est crédible lorsque la valeur foncière est supérieure à 5000** (en-dessous, il s'agit d'une vente qui ne nous intéresse pas).\n",
    "\n",
    "De même, pn considère qu'**une transaction est crédible lorsque la surface du bâtiment est supérieure à 10 m2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef4ffc-61e3-4bb4-a371-334557cb78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'abord, on écarte les valeurs foncières inférieures à 5000 et les surface_reelle_bati inférieures à 10 m2\n",
    "\n",
    "data = data[data[\"valeur_fonciere\"] > 4999]\n",
    "\n",
    "data = data[data[\"surface_reelle_bati\"] > 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26648287-8a0f-4876-b7cc-859c24029003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il n'y a plus de Dépendances dans le dataset...\n",
    "\n",
    "data[\"type_local\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2d042-830c-4a43-946e-4e5e4b6dcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"code_postal\", \"longitude\", \"latitude\"], axis = 1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12def0",
   "metadata": {},
   "source": [
    "Par ailleurs, on observe avec le describe ci-dessus que **les écart-types sont très importants par rapport aux moyennes**, surtout pour les variables \"valeur_fonciere\", \"surface_reelle_bati\" et \"surface_terrain\".\n",
    "Donc, **on enlève les valeurs trop hautes** : ici, cela consiste à *enlever les valeurs dont l'écart à la moyenne en valeur absolue est supérieure à 4 fois l'écart-type*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fd9ae-9b98-4f21-a8e3-6ff291915cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour valeur_fonciere :\n",
    "data = data[~(np.abs(data['valeur_fonciere'] - data['valeur_fonciere'].mean()) > (4 * data['valeur_fonciere'].std()))]\n",
    "\n",
    "# Pour surface_reelle_bati :\n",
    "data = data[~(np.abs(data['surface_reelle_bati'] - data['surface_reelle_bati'].mean()) > (4 * data['surface_reelle_bati'].std()))]\n",
    "\n",
    "# Pour surface_terrain :\n",
    "data = data[~(np.abs(data['surface_terrain'] - data['surface_terrain'].mean()) > (4 * data['surface_terrain'].std()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd67371-0051-4e27-9f5d-d71d23f91cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"code_postal\", \"longitude\", \"latitude\"], axis = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4d2c7-8d21-409f-9f3f-e251244cd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e90ee2-831f-45ea-886d-5dc9d01825ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"valeur_fonciere\", y = \"type_local\", data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83266d3a-9c92-4e26-8f27-1f71af2eede5",
   "metadata": {},
   "source": [
    "**Ces boxplots correspondent davantage avec la réalité** (médiane des ventes autour de 150 000 euros)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22368a66-1ae1-49c9-a4c5-4a4d592e9b83",
   "metadata": {},
   "source": [
    "# Etape 2 : feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25bbd4-2a55-4776-8ad3-cd1d217d5f0d",
   "metadata": {},
   "source": [
    "### 2.1. Choix des nouveaux features :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c58b8-a9f7-4f1e-a6f4-4d6c51675f1a",
   "metadata": {},
   "source": [
    "Afin d'**avoir un modèle performant**, nous allons **ajouter d'autres features**. En effet, la localisation, le prix, le nombre de pièces et la surface ne donnent pas assez d'informations pour bien valoriser un bien immobilier.\n",
    "\n",
    "Selon BSI Economics, **trois facteurs** qui influencent les prix de l'immobilier :\n",
    "\n",
    "- **l'environnement économique et financier** (offre et demande de logement, contexte économie, structure des marchés immobiliers, logements neufs et anciens, démographie, taux de logements vacants) ;\n",
    "\n",
    "- **les conditions d'emprunts** (taux variables/fixes, maturités des prêts, ratio emprunt sur valeur, répartition des crédits, solvabilité, système de garantie) ;\n",
    "\n",
    "- **l'environnement fiscal** (mesures fiscales incitatives à la location, distorsion fiscale des locataires vers les propriétaires).\n",
    "\n",
    "En particulier, **un agent immobilier** observe, par exemple, les features suivant :\n",
    "* prix au m2 du quartier (le projet qui nous a inspiré utilise l'algorithme BallTree pour l'obtenir), \n",
    "* PIB du département (mesure de l'activité économique des alentours), \n",
    "* densité du département (mesure de l'urbanisation, de l'activité), \n",
    "* variation de population non naturelle (mesure de l'attractivité),\n",
    "* mois de la transaction (saisonnalité des prix dans certaines régions touristiques), \n",
    "* taux de logements vacants dans la région (mesure de l'attractivité)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982917b4-89eb-4edb-9402-11d30a223b93",
   "metadata": {},
   "source": [
    "### 2.2. Importation des nouveaux features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00858cc-57c6-470e-beb4-9c414e7c1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de la variable prix_m2 :\n",
    "data['prix_m2'] = data['surface_terrain'] / data['valeur_fonciere']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35f454-fb92-485c-8383-c806b72343e8",
   "metadata": {},
   "source": [
    "Ces features ont été **générées dans le notebook \"external-data\"**. Nous invitons le lecteur à s'y référer afin d'apprécier la manière dont ils ont été importés puis préprocessés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358982c-0878-497e-a14c-f6e41c3c5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données externes INSEE :\n",
    "\n",
    "#Old via excel\n",
    "#file_path = \"https://github.com/victor-kerros/tokenisation-immo/raw/main/external-data.csv\"\n",
    "#external_data = pd.read_csv(file_path, sep = \",\")\n",
    "\n",
    "external_data = retrieve_data()\n",
    "external_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5a8fa-ffe8-4b0a-887c-708c7ac150d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "data[\"code_departement\"] = data[\"code_departement\"].apply(\n",
    "    lambda dep: str(dep) if str(dep) not in list_numbers else \"0\"+str(dep))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a515955-275f-4822-af71-c57124699e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vente = data[\"code_departement\"].unique()\n",
    "dep_commun = external_data[\"code_dep\"].unique()\n",
    "\n",
    "print(f\"Département présents dans les ventes mais pas dans nos données complémentaires : \\\n",
    "      {[code_dep for code_dep in dep_vente if code_dep not in dep_commun]}\")\n",
    "print(f\"Département présents dans les données complémentaires mais pas dans les ventes : \\\n",
    "{[code_dep for code_dep in dep_commun if code_dep not in dep_vente]}\")\n",
    "print(f\"Nombre de départements uniques dans notre table générale : {len(data['code_departement'].unique())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0f421-7c95-4508-bdb2-b8bc35067d0f",
   "metadata": {},
   "source": [
    "Les Landes (40) sont présentes dans les ventes mais **pas dans nos données complémentaires** (à cause du df chômage)...\n",
    "Par ailleurs, il n'y a que **97 départements uniques** dans notre table générale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9877aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Nombre de lignes correspondant aux Landes qui vont être perdues\")\n",
    "display(data[data[\"code_departement\"] == '40'][\"code_departement\"].count())\n",
    "display(\"Longueur avant inner join :\")\n",
    "len_pre_join = data.shape[0]\n",
    "display(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a8444-dacd-49ed-ae7a-e92c591a81df",
   "metadata": {},
   "source": [
    "### 2.3. Jointure des deux tables de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92d6c4-6092-4ea2-83ac-2caeeb1f0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(\"code_departement\").join(external_data.set_index(\"code_dep\"), how = \"inner\", rsuffix = \"jo\")\n",
    "data = data.reset_index().rename(columns = {\"index\": \"code_departement\"})\n",
    "display(\"Longueur après inner join :\")\n",
    "display(data.shape[0])\n",
    "len_post_join = data.shape[0]\n",
    "display(\"Lignes perdues pendant la jointure (du fait de l'inner join) :\")\n",
    "display(abs(len_post_join - len_pre_join))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637764bd",
   "metadata": {},
   "source": [
    "L'inner join avec les autres features nous fait perdre les 1799 lignes correspondant aux ventes dans le département 40, comme on pouvait s'y attendre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151b27a-402f-4768-82f2-cb868b8badec",
   "metadata": {},
   "source": [
    "La base de donnée est bien cleanée avec **les nouveaux features ajoutés**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a528f0b-5130-48b6-bfb2-e86df6940e2b",
   "metadata": {},
   "source": [
    "# Etape 3 : analyse descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb7c9b-63a1-4b11-8411-9e74d8417292",
   "metadata": {},
   "source": [
    "### 3.1. Premières analyses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270d9db-efc8-466b-ae8e-2c41d385d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des lignes :\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392150f-b49b-488e-a0cc-18e3c78df0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des valeurs uniques dans les colonnes \"nature_culture\" et \"type_local\" :\n",
    "\n",
    "display(data[\"nature_culture\"].unique())\n",
    "display(data[\"type_local\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bc4db-183d-4b6a-8df1-fd2d9fba9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_maisons = list(data[\"type_local\"]).count(\"Maison\")\n",
    "print(f\"Le nombre de maisons dans le dataset est : {nb_maisons}.\")\n",
    "\n",
    "nb_appartement = list(data[\"type_local\"]).count(\"Appartement\")\n",
    "print(f\"Le nombre d'appartments dans le dataset est : {nb_appartement}.\")\n",
    "\n",
    "nb_local = list(data[\"type_local\"]).count(\"Local industriel. commercial ou assimilé\")\n",
    "print(f\"Le nombre de 'Local industriel. commercial ou assimilé' dans le dataset est : {nb_local}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291599d-15c1-4233-b402-9a47f17bcbe5",
   "metadata": {},
   "source": [
    "### 3.2. Analyse de la répartition des ventes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f953e-2f4b-49ce-8b28-4b1a709cf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des prix de vente :\n",
    "\n",
    "plt.hist(data[\"valeur_fonciere\"].values, bins = 100)\n",
    "plt.title('Répartition des valeurs foncières')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f645a-8477-4a1e-86d4-c304996c4d04",
   "metadata": {},
   "source": [
    "Il y a encore des valeurs extrêmes qui **gênent la visualisation**. Nous allons **renlever les valeurs extrêmes** pour pouvoir mieux observer les données (nous enlevons les valeurs foncières dont l'écart à la moyenne est supérieur à 2,5 fois l'écart type). \n",
    "\n",
    "**Attention** : nous n'enlevons pas ces données de notre dataset principal (pour cela, nous créons data_aux).\n",
    "\n",
    "On constate que la distribution est celle d'une **loi exponentielle**.\n",
    "\n",
    "N.B. : nous utilisons également **le package seaborn** qui offre de bonnes opportunités de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369b8c5-b02b-4f0c-9ffb-ef3f22081336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = data[~(np.abs(data['valeur_fonciere'] - data['valeur_fonciere'].mean()) > (2.5 * data['valeur_fonciere'].std()))]\n",
    "\n",
    "sns.displot(data_aux, \n",
    "            x = \"valeur_fonciere\", \n",
    "            bins = 50)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0ae99-698d-445e-9d8b-a108430638e0",
   "metadata": {},
   "source": [
    "Distinguons les **types de biens** désormais :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65975bfa-0bd5-4368-b7b8-a5d6c44162f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = data_aux.drop(data_aux.loc[data_aux['type_local'] == 'Local industriel. commercial ou assimilé'].index)\n",
    "\n",
    "sns.displot(data = data_aux,\n",
    "            x = \"valeur_fonciere\",\n",
    "            hue = \"type_local\",\n",
    "            element = \"step\")\n",
    "\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4598431-9519-4841-b630-28196d004a36",
   "metadata": {},
   "source": [
    "On constate sur ce graphique que, dans ce dataset (\"data_aux\"), **les valeurs foncières des maisons sont sont en moyenne légèrement plus élevées que celles des appartements**. Cependant, cela est lié au fait que **nous avons tronqué le dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bfbb7-b1b3-4c56-a6dc-0b2fd03e77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prix moyen des maisons : {np.round(data.loc[data['type_local'] == 'Maison']['valeur_fonciere'].mean())}\")\n",
    "print(f\"Prix moyen des appartements : {np.round(data.loc[data['type_local'] == 'Appartement']['valeur_fonciere'].mean())}\")\n",
    "\n",
    "print(f\"Ecart-type des prix des maisons : {np.round(data.loc[data['type_local'] == 'Maison']['valeur_fonciere'].std())}\")\n",
    "print(f\"Ecart-type des prix des appartements : {np.round(data.loc[data['type_local'] == 'Appartement']['valeur_fonciere'].std())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b098d0-28b9-4cf1-938e-c855806e3d1a",
   "metadata": {},
   "source": [
    "En effet, le prix moyen des appartements est très légèrement plus élevé que le prix moyen des maisons mais **l'écart-type des prix des appartements est sensiblement plus élevé que celui des maisons**.\n",
    "\n",
    "Cela s'interprète par le fait que **les appartements dans les centres grandes villes sont largement majoritaires et très chers** (il y a peu de maisons dans ces zones, s'il y en a elles sont très très chères mais il y a trop peu pour que cela ait un impact sur la variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd78845-cfdc-41df-a05d-f92fb90e5ad6",
   "metadata": {},
   "source": [
    "### 3.3. Corrélation entre valeur foncière et surface :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62662709-e272-4659-bf49-36b1d01b81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation des transactions d'appartements et maisons : valeur foncière en fonction de la surface\n",
    "\n",
    "data_aux = data_aux.drop(data_aux.loc[data_aux['type_local'] == 'Dépendance'].index)\n",
    "\n",
    "ax = sns.relplot(x = \"surface_reelle_bati\", \n",
    "            y = \"valeur_fonciere\", \n",
    "            hue = \"type_local\", \n",
    "            data = data_aux.sample(2000))\n",
    "ax.set(title = \"Relation entre valeur foncière et surface du bâti\",\n",
    "       xlabel = \"Surface réelle bâti\", ylabel = \"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ab1bd-bc65-40b0-9c2a-314092804b29",
   "metadata": {},
   "source": [
    "On ne constate **pas une corrélation très marquée**... En effet, il faudrait **distinguer la localisation** du bien (Paris vs. petite ville vs. campagne)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0785b2c-6334-49d9-9a4a-4c97a55353f3",
   "metadata": {},
   "source": [
    "### 3.4. Premières intuitions sur l'analyse à l'échelle départementale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5235f-4651-4ef5-a749-0bf89d8d2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation des transactions d'appartements et maisons pour Paris\n",
    "\n",
    "data_aux_paris = data.drop(data.loc[data['code_departement'] != \"75\"].index)\n",
    "\n",
    "data_aux_paris = data_aux_paris.drop(data_aux_paris.\n",
    "                                     loc[data_aux_paris['type_local'] =='Local industriel. commercial ou assimilé'].index)\n",
    "\n",
    "ax = sns.relplot(x = \"surface_reelle_bati\", \n",
    "            y = \"valeur_fonciere\", \n",
    "            hue = \"type_local\", \n",
    "            data = data_aux_paris.sample(10000))\n",
    "ax.set(title = \"Relation entre valeur foncière et surface du bâti\",\n",
    "       xlabel = \"Surface réelle bâti\", ylabel = \"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff740a84-4cd8-4a29-bd25-95628687bfee",
   "metadata": {},
   "source": [
    "**Observation de la corrélation** avec lmplot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ff4d5-fe98-4f96-8a1a-a0eb7d7fcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(x = \"surface_reelle_bati\", \n",
    "            y = \"valeur_fonciere\", \n",
    "            hue = \"type_local\", \n",
    "            data = data_aux_paris.sample(10000))\n",
    "ax.set(title = \"Relation entre valeur foncière et surface du bâti\",\n",
    "       xlabel = \"Surface réelle bâti\", ylabel = \"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df368788-b096-4e17-a118-003beab40b69",
   "metadata": {},
   "source": [
    "Pour la ville de Paris, la corrélation est très marquée !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c486b-635a-459d-b0d6-273aa147266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation des transactions d'appartements et maisons pour le Finistère\n",
    "\n",
    "data_aux_finistere = data.drop(data.loc[data['code_departement'] != \"29\"].index)\n",
    "data_aux_finistere = data_aux_finistere.drop(data_aux_finistere.loc[data_aux_finistere['type_local'] == 'Local industriel. commercial ou assimilé'].index)\n",
    "display(data_aux_finistere.shape)\n",
    "\n",
    "ax = sns.lmplot(x = \"surface_reelle_bati\", \n",
    "            y = \"valeur_fonciere\", \n",
    "            hue = \"type_local\", \n",
    "            data = data_aux_finistere.sample(200))\n",
    "ax.set(title = \"Relation entre valeur foncière et surface du bâti\",\n",
    "       xlabel = \"Surface réelle bâti\", ylabel = \"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2eb12",
   "metadata": {},
   "source": [
    "### 3.5. Analyse par département :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930a480-7c3b-45c8-b36c-45c3f42f3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les départements où les prix moyens des transaction sont les plus élevés :\n",
    "\n",
    "ranking_dpt_mean_price = data.groupby(\"code_departement\")[\"valeur_fonciere\"].mean().sort_values(ascending = False)\n",
    "\n",
    "print(\"Les cinq départements où les prix moyens des transaction sont les plus élevés :\")\n",
    "display(pd.DataFrame(ranking_dpt_mean_price).head(5))\n",
    "\n",
    "print(\"Visualisation graphique des 20 départements où les prix moyens des transaction sont les plus élevés :\")\n",
    "fig, axs = plt.subplots()\n",
    "axs.set(title = \"Prix moyen de la transaction par départements\")\n",
    "axs.bar(x = [str(dep) for dep in ranking_dpt_mean_price.head(20).index.unique()],\n",
    "            height = ranking_dpt_mean_price.head(20) )\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a5fb6-a87e-4f35-8074-5c473b045fc5",
   "metadata": {},
   "source": [
    "Sans surprise, **les départements de la région parisienne sont en tête du classement** des départements où les prix moyens des transaction sont les plus élevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35cd1e-dfdf-43b0-8608-d42e68915db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les départements où il y a eu le plus de transactions :\n",
    "\n",
    "ranking_dpt_nb = data.groupby(\"code_departement\")[\"valeur_fonciere\"].count().sort_values(ascending = False)\n",
    "print(\"Les cinq départements où il y a eu le plus de transactions :\")\n",
    "display(pd.DataFrame(ranking_dpt_nb).head(5))\n",
    "\n",
    "print(\"Visualisation graphique des 20 départements où il y a eu le plus de transactions :\")\n",
    "fig, axs = plt.subplots()\n",
    "axs.set(title = \"Nombre de transaction par départements\")\n",
    "axs.bar(x = [str(dep) for dep in ranking_dpt_nb.head(20).index.unique()],\n",
    "            height = ranking_dpt_nb.head(20) )\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027335f8-af0c-4a9a-a78b-e775e2637a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les départements où les nombres moyens de m2 sont les plus élevés :\n",
    "\n",
    "ranking_dpt_nb_m2 = data.groupby(\"code_departement\")[\"surface_reelle_bati\"].mean().sort_values(ascending = False)\n",
    "print(\"Les cinq départements où les nombres moyens de m2 sont les plus élevés :\")\n",
    "display(pd.DataFrame(ranking_dpt_nb_m2).head(5))\n",
    "\n",
    "print(\"Visualisation graphique des 20 départements où les nombres moyens de m2 sont les plus élevés :\")\n",
    "fig, axs = plt.subplots()\n",
    "axs.set(title = \"Nombre de transaction par départements\")\n",
    "axs.bar(x = [str(dep) for dep in ranking_dpt_nb_m2.head(20).index.unique()],\n",
    "            height = ranking_dpt_nb_m2.head(20) )\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf71af",
   "metadata": {},
   "source": [
    "### 3.6. QQ-plot :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637232a9-9f6a-4f94-b166-be3589037cbe",
   "metadata": {},
   "source": [
    "Les QQ-plot pour la variable \"valeurs foncières\" correspondent à ceux d'une **distribution exponentielle**, ce qui confirme notre intuition sur la répartition des valeurs foncières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d2bb6-c4bf-4663-93d3-2ce692490fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(data[\"valeur_fonciere\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(data[\"valeur_fonciere\"], plot = plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49a80-59a4-450c-ab54-c21363dfb9e5",
   "metadata": {},
   "source": [
    "### 3.7. Représentation cartographique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f3821-335c-4d05-910a-5d128d49e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = data[data['code_departement'] == \"75\"]\n",
    "sub_data = sub_data[sub_data['longitude'].notna()]\n",
    "sub_data = sub_data[sub_data['latitude'].notna()]\n",
    "sub_data = sub_data.sample(1000).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0db2f-680e-4cff-823e-781051817f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = folium.Map(location = [48.856578, 2.351828], zoom_start = 12)\n",
    "coord = [float(sub_data['latitude'][0]), float(sub_data['longitude'][0])]\n",
    "id_ = str(sub_data[\"identifiant_transaction\"][0]) + \"au prix : \" + str(sub_data[\"valeur_fonciere\"][0])\n",
    "folium.CircleMarker(coord, \n",
    "                    popup = id_, \n",
    "                    radius = 2).add_to(paris)\n",
    "\n",
    "for index in tqdm(range(sub_data.shape[0]), desc = \"Progression\"):\n",
    "    coord = [float(sub_data[\"latitude\"][index]), float(sub_data[\"longitude\"][index])]\n",
    "    id_ = str(sub_data[\"identifiant_transaction\"][index]) + \" au prix : \" + str(sub_data[\"valeur_fonciere\"][index])\n",
    "    folium.CircleMarker(coord, \n",
    "                        popup = id_, \n",
    "                        radius = 2).add_to(paris)\n",
    "    \n",
    "paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc46b0-b439-4ad5-ac33-45f860c6735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = data[data['longitude'].notna()]\n",
    "sub_data = sub_data[sub_data['latitude'].notna()]\n",
    "sub_data = sub_data.sample(10000).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5808e12-a7b8-4722-9c48-cc6abac042d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "france = folium.Map(location = [46.227638, 2.213749], zoom_start = 5)\n",
    "coord = [float(sub_data['latitude'][0]), float(sub_data['longitude'][0])]\n",
    "id_ = str(sub_data[\"identifiant_transaction\"][0]) + \"au prix : \" + str(sub_data[\"valeur_fonciere\"][0])\n",
    "folium.CircleMarker(coord, \n",
    "                    popup = id_, \n",
    "                    radius = 2).add_to(france)\n",
    "\n",
    "for index in tqdm(range(sub_data.shape[0]), desc = \"Progression\"):\n",
    "    coord = [float(sub_data[\"latitude\"][index]), float(sub_data[\"longitude\"][index])]\n",
    "    id_ = str(sub_data[\"identifiant_transaction\"][index]) + \" au prix : \" + str(sub_data[\"valeur_fonciere\"][index])\n",
    "    folium.CircleMarker(coord, \n",
    "                        popup = id_, \n",
    "                        radius = 2).add_to(france)\n",
    "    \n",
    "france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c54e8-0e14-49d2-806c-7261c42e5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lien tuto folium : https://fxjollois.github.io/cours-2016-2017/analyse-donnees-massives-tp9.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432561d-749a-45d0-8188-17b479153aa0",
   "metadata": {},
   "source": [
    "# Etape 4 : modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82344581",
   "metadata": {},
   "source": [
    "**Imports pour la modélisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1555735",
   "metadata": {},
   "source": [
    "#### Fixer une graine pour l'aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33b6ab",
   "metadata": {},
   "source": [
    "*Noter qu'il aurait fallu faire de la cross-validation pour éviter la variabilité*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b060304",
   "metadata": {},
   "source": [
    "### 4.1 Métriques et variables \"dummies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2760c76",
   "metadata": {},
   "source": [
    "**Concernant le choix des métriques d'évaluation des modèles** \n",
    "Ici on cherche à prédire le plus précisemment possible la valeur du logement à partir de ses caractéristiques.\n",
    "Les métriques utilisées sont :\n",
    "- *R2*\n",
    "- *Mean_squarred_error* \"expected value of the squarred error\"\n",
    "- *MAPE*: mean absolute percentage error, mesure de la précision comme un pourcentage. Noter que cette métrique peut prendre des valeurs supérieures à 100, elle représente en quelque sorte un pourcentage moyen\n",
    "\n",
    "Etant donné que ce qui nous intéresse dans ce projet est de prédire précisemment le prix du logement, la métrique **MAPE** \n",
    "semble la plus pertinente puisqu'elle nous donne une mesure en pourcentage de la précision de notre estimation (ou plutôt de l'écart en % de notre prédiction à la réalité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4893-16fe-4bb2-9d95-eb99ee727c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection\n",
    "\n",
    "data_model = data\n",
    "features = ['valeur_fonciere', 'type_local', 'surface_reelle_bati', 'nombre_pieces_principales', \n",
    "            'nature_culture', 'surface_terrain', 'code_departement', 'tx_natalite_2020_percent', \n",
    "            'nb_musees', 'chomage_2016', 'chomage_2017', 'chomage_2018', 'chomage_2019',\n",
    "           'chomage_2020', 'chomage_2019', 'taux_vacances_2019']\n",
    "\n",
    "data_model = data_model[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0556900",
   "metadata": {},
   "source": [
    "Etant donné que le modèle de randomforest de sklearn ne peut pas gérer seul les variables catégorielles, nous devons les \n",
    "transformer en dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b0575-d735-44a5-91d8-9505d3d11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "# Nous avons découvert trop tard que faire des dummies n'est pas optimal pour les random forest\n",
    "\n",
    "# local_type\n",
    "\n",
    "data_model[\"encoded_local_type_m\"] = [1 if local == \"Maison\" else 0 for local in data_model[\"type_local\"]]\n",
    "data_model[\"encoded_local_type_a\"] = [2 if local == \"Appartement\" else 0 for local in data_model[\"type_local\"]]\n",
    "data_model[\"encoded_local_type_d\"] = [3 if local == \"Dépendance\" else 0 for local in data_model[\"type_local\"]]\n",
    "data_model[\"encoded_local_type_l\"] = [4 if local == \"Local industriel. commercial ou assimilé\" else 0 \\\n",
    "                                      for local in data_model[\"type_local\"]]\n",
    "\n",
    "\n",
    "list_name = [\"type_local\", \"encoded_local_type_m\", \"encoded_local_type_a\", \"encoded_local_type_d\", \n",
    "             \"encoded_local_type_l\"]\n",
    "\n",
    "data_model[\"encoded_local_type\"] = data_model.loc[:,list_name].sum(axis = 1)\n",
    "data_model = data_model.drop(list_name, axis = 1)\n",
    "\n",
    "# nature_culture\n",
    "\n",
    "data_model[\"encoded_nature_culture_c\"] = [1 if local == \"culture\" else 0 for local in data_model[\"nature_culture\"]]\n",
    "data_model[\"encoded_nature_culture_s\"] = [2 if local == \"sols\" else 0 for local in data_model[\"nature_culture\"]]\n",
    "data_model[\"encoded_nature_culture_tb\"] = [3 if local == \"terrains a bâtir\" else 0 for local in data_model[\"nature_culture\"]]\n",
    "data_model[\"encoded_nature_culture_j\"] = [4 if local == \"jardins\" else 0 for local in data_model[\"nature_culture\"]]\n",
    "data_model[\"encoded_nature_culture_ta\"] = [4 if local == \"terrains d'agrément\" else 0 for local in data_model[\"nature_culture\"]]\n",
    "\n",
    "list_name = [\"nature_culture\", \"encoded_nature_culture_c\", \"encoded_nature_culture_s\", \n",
    "             \"encoded_nature_culture_tb\", \"encoded_nature_culture_j\", \"encoded_nature_culture_ta\"]\n",
    "\n",
    "data_model[\"encoded_nature_culture\"] = data_model.loc[:,list_name].sum(axis = 1)\n",
    "\n",
    "data_model = data_model.drop(list_name, axis = 1)\n",
    "\n",
    "# code_departement\n",
    "\n",
    "data_model[\"code_departement\"] = [201 if code == \"2A\" else code for code in data_model[\"code_departement\"]]\n",
    "data_model[\"code_departement\"] = [202 if code == \"2B\" else code for code in data_model[\"code_departement\"]]\n",
    "\n",
    "# departement en ordinal\n",
    "# même si cela crée un biais\n",
    "\n",
    "data_model[\"dep_order\"] = data_model[\"code_departement\"]\n",
    "data_model[\"dep_order\"] = data_model[\"dep_order\"].apply(lambda dep: float(dep))\n",
    "\n",
    "# enlever NaN (on les remplace par des 0, à justifier)\n",
    "data_model = data_model.fillna(0)\n",
    "\n",
    "data_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f2990",
   "metadata": {},
   "source": [
    "### 4.2. Entraînement de modèles sur tous les départements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8996b0",
   "metadata": {},
   "source": [
    "**Régression linéaire simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de11d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_small = data_model.copy()\n",
    "data_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_small = data_model_small[[\"surface_reelle_bati\", \"valeur_fonciere\"]]\n",
    "data_model_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d42286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle régression linéaire simple\n",
    "\n",
    "training_data, test_data = train_test_split(data_model_small, test_size = 0.2)\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = LinearRegression(fit_intercept = True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346277ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle régression linéaire simple\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903877a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients du modèle régression linéaire simple\n",
    "\n",
    "print(\"Intercept: \\n\", model.intercept_)\n",
    "print(\"Coefficients: \\n\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle régression linéaire simple\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e284347",
   "metadata": {},
   "source": [
    "Ce modèle extrêmement simple explique seulement **6.5%** de la variance dans les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8f8c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.scatter(X_test, y_test, color = \"black\", s = 1)\n",
    "axs.plot(X_test, y_pred, color = \"blue\", linewidth = 3)\n",
    "axs.set_xlabel(\"Surface réelle bâtie\")\n",
    "axs.set_ylabel(\"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ac007",
   "metadata": {},
   "source": [
    "Le graphique ci-dessus indique les vrais points de données (en noir) et la droite de la régression linéaire simple (en bleue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e5e72",
   "metadata": {},
   "source": [
    "**Régression linéaire multiple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle régression linéaire multiple\n",
    "\n",
    "training_data, test_data = train_test_split(data_model[[\"valeur_fonciere\",\"surface_reelle_bati\", \"nombre_pieces_principales\",\n",
    "                                                       \"surface_terrain\", \"encoded_local_type\", \"encoded_nature_culture\",\n",
    "                                                       \"dep_order\"]],\n",
    "                                            test_size = 0.2)\n",
    "\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = LinearRegression(fit_intercept = True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65771356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle régression linéaire multiple\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients du régression linéaire multiple\n",
    "print(\"Intercept: \\n\", model.intercept_)\n",
    "print(\"Coefficients: \\n\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle régression linéaire multiple\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee43e23",
   "metadata": {},
   "source": [
    "Ici, on monte à seulement **11 %** de variance expliquée en y rajoutant plein de variables, ce qui est assez peu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab7671",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde284a5-4ebd-45fa-a371-09081f62c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle random forest\n",
    "\n",
    "training_data, test_data = train_test_split(data_model[[\"valeur_fonciere\",\"surface_reelle_bati\", \"nombre_pieces_principales\",\n",
    "                                                       \"surface_terrain\", \"encoded_local_type\", \"encoded_nature_culture\",\n",
    "                                                       \"dep_order\"]], test_size = 0.2)\n",
    "\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 30, min_samples_split = 5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccb6e3-1963-4c56-92fe-18e6da09dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle random forest\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e368914-167d-4455-9e5c-f9629cae09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle random forest\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687b98d",
   "metadata": {},
   "source": [
    "On constate que la part de variance expliquée par le modèle monte à près de **51%**. Notre métrique MAPE reste cependant très élevée (>50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b77649-4c8f-4177-9582-66615b1165b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.DataFrame((np.abs(y_test - model.predict(X_test)) / y_test)) * 100\n",
    "\n",
    "schema.hist(bins = 200)\n",
    "\n",
    "plt.xlabel('Erreur en %')\n",
    "plt.title('Distribution de l\\'erreur de notre modèle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe81c7",
   "metadata": {},
   "source": [
    "Il semble que l'erreur de notre modèle soit tirée vers le haut par quelques points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8194a0",
   "metadata": {},
   "source": [
    "#### Random forest incluant les données externes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77362f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle random forest avec les données externes\n",
    "\n",
    "training_data, test_data = train_test_split(data_model.drop([\"code_departement\"], axis =1), test_size = 0.2)\n",
    "\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 30, min_samples_split = 5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle random forest avec les données externes\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle random forest avec les données externes\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31cc01",
   "metadata": {},
   "source": [
    "Ici, l'ajout de différentes données concernant les départements semblent peu pertinentes. En effet, elle ne fait agumenter le R2 que de 2% et fait même augmenter le MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331fe73",
   "metadata": {},
   "source": [
    "### 4.3 Entraînement restreint à Paris 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399510c9",
   "metadata": {},
   "source": [
    "#### Création du sous-jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ae24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_75 = data_model[['valeur_fonciere', 'surface_reelle_bati', 'nombre_pieces_principales',\n",
    "       'surface_terrain', 'code_departement',  'encoded_local_type','encoded_nature_culture']]\n",
    "data_model_75 = data_model_75[data_model_75[\"code_departement\"] == \"75\"].drop(\"code_departement\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_75.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0464d4d",
   "metadata": {},
   "source": [
    "#### Régression linéaire simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle régression linéaire simple pour Paris\n",
    "\n",
    "training_data, test_data = train_test_split(data_model_75[[\"valeur_fonciere\",\"surface_reelle_bati\"]], test_size = 0.2)\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = LinearRegression(fit_intercept = True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5659c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle régression linéaire simple\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients du modèle régression linéaire simple\n",
    "\n",
    "print(\"Intercept: \\n\", model.intercept_)\n",
    "print(\"Coefficients: \\n\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle régression linéaire simple\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33bdb75",
   "metadata": {},
   "source": [
    "Cette régression linéaire toute simple explique ici 52 % de la variance ! Mais le MAPE est très élevée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.scatter(X_test, y_test, color = \"black\", s = 1)\n",
    "axs.plot(X_test, y_pred, color = \"blue\", linewidth = 3)\n",
    "axs.set_xlabel(\"Surface réelle bâtie\")\n",
    "axs.set_ylabel(\"Valeur foncière\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52bac2",
   "metadata": {},
   "source": [
    "On constate visuellement que pour Paris, une régression linéaire simple sur la surface relle batie permet d'expliquer une grand part de la variation dans les données (à part quelques données aberrantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615cca38",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751693e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle random forest avec les données externes\n",
    "\n",
    "training_data, test_data = train_test_split(data_model_75, test_size = 0.2)\n",
    "\n",
    "y_train = training_data[\"valeur_fonciere\"].values\n",
    "X_train = training_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 30, min_samples_split = 5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du modèle random forest avec les données externes\n",
    "\n",
    "y_test = test_data[\"valeur_fonciere\"].values\n",
    "X_test = test_data.drop([\"valeur_fonciere\"], axis = 1).values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b995b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques du modèle random forest avec les données externes\n",
    "\n",
    "display(\"MAPE\")\n",
    "display(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "display(\"MSE (e9)\")\n",
    "display(mean_squared_error(y_test, y_pred)/10**9)\n",
    "\n",
    "display(\"R2\")\n",
    "display(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14881add",
   "metadata": {},
   "source": [
    "Utiliser random forest permet de faire monter un peu le R2 de 15% ici, mais le MAPE reste toujours très élevé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc52dc",
   "metadata": {},
   "source": [
    "#### Conclusion principale de la modélisation\n",
    "* L'utilisation de random forest nous permet de modéliser environ 50% de la variance dans les données\n",
    "* Les données supplémentaires sur les départements ne semblent pas ici tèrs pertinentes\n",
    "* Si l'on restreint le jeu de données à Paris, une régression linéaire simple semble très performante, elle pourrait l'être encore plus en enlevant quelques points aberrants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
