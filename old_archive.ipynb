{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45f060a",
   "metadata": {},
   "source": [
    "**1 - Fonctions autre projet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54da40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions d'entraînement du modèle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def train_model(training_data, params, features):\n",
    "\n",
    "    model = {}\n",
    "    df_features, target = split_target_features(training_data, \"valeur_fonciere\")\n",
    "\n",
    "    encoder_model = fit_encode_features(df_features, features)\n",
    "    x_train, encoded_features_name = transform_encode_features(\n",
    "        encoder_model, df_features, features\n",
    "    )\n",
    "\n",
    "    regression_model = RandomForestRegressor(params)\n",
    "    regression_model.fit(x_train[encoded_features_name].values, target.values)\n",
    "\n",
    "    model[\"encoder\"] = encoder_model\n",
    "    model[\"regressor\"] = regression_model\n",
    "    model[\"feature_name\"] = features\n",
    "\n",
    "    return model, params\n",
    "\n",
    "\n",
    "def split_target_features(data: pd.DataFrame, target_name: str):\n",
    "\n",
    "    features = [feat for feat in data.columns if feat != target_name]\n",
    "    assert target_name not in features\n",
    "    return data[features], data[target_name]\n",
    "\n",
    "\n",
    "def fit_encode_features(df_features: pd.DataFrame, features_name: list):\n",
    "\n",
    "    cat_features = df_features.select_dtypes(\"object\")\n",
    "    encoders = dict()\n",
    "    for col in cat_features.columns:\n",
    "        if col not in features_name:\n",
    "            continue\n",
    "        encoder = LabelEncoder()\n",
    "        encoder = encoder.fit(list(df_features[col]) + [\"unknown\"])\n",
    "        encoders[col] = encoder\n",
    "\n",
    "    return encoders\n",
    "\n",
    "\n",
    "def transform_encode_features(encoders, df_features: pd.DataFrame, features: list, suffix: str = \"_cat\"):\n",
    "\n",
    "    encoded_features_name = features.copy()\n",
    "    for col in encoders.keys():\n",
    "        if col not in features:\n",
    "            continue\n",
    "        col_cat = col + suffix\n",
    "        new_df_col = list(df_features[col])\n",
    "        for unique_item in np.unique(df_features[col]):\n",
    "            if unique_item not in encoders[col].classes_:\n",
    "                new_df_col = [\"unknown\" if x == unique_item else x for x in new_df_col]\n",
    "        df_features[col_cat] = encoders[col].transform(new_df_col)\n",
    "        df_features[col_cat] = df_features[col_cat].astype(\"category\")\n",
    "        encoded_features_name.remove(col)\n",
    "        encoded_features_name += [col_cat]\n",
    "\n",
    "    return df_features, encoded_features_name\n",
    "\n",
    "\n",
    "def predict_price(df_features, model, features):\n",
    "    \"\"\"\n",
    "    Predict demand by encoding categorical variables and using the regressor model.\n",
    "    \"\"\"\n",
    "    x_test, encoded_features_name = transform_encode_features(\n",
    "        model[\"encoder\"], df_features.copy(), features\n",
    "    )\n",
    "    predicted_data = model[\"regressor\"].predict(x_test[encoded_features_name].values)\n",
    "    return predicted_data\n",
    "\n",
    "\n",
    "def mae(y_true: pd.Series, y_pred: pd.Series, in_percent: bool = False) -> float:\n",
    "\n",
    "    assert len(y_true) > 0, \"MAE need at least one actual\"\n",
    "    assert len(y_pred) > 0, \"MAE needs at least one prediction\"\n",
    "\n",
    "    if in_percent:\n",
    "        return 100 * np.sum(np.abs(y_pred - y_true)) / len(y_true)\n",
    "\n",
    "    return np.sum(np.abs(y_pred - y_true)) / len(y_true)\n",
    "\n",
    "\n",
    "def evaluate(y, y_hat, method):\n",
    "\n",
    "    if method == \"mae\":\n",
    "        score = mae(y, y_hat)\n",
    "    elif method == \"wmape\":\n",
    "        score = wmape(y, y_hat)\n",
    "    elif method == \"smape\":\n",
    "        score = smape(y, y_hat)\n",
    "    elif method == \"r2\":\n",
    "        score = r2(y, y_hat)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method for backtest: {method}\")\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def backtest_model(test_data, model, features):\n",
    "\n",
    "    df_feature, target = split_target_features(test_data, \"valeur_fonciere\")\n",
    "    predicted_data = predict_price(df_feature, model, features)\n",
    "    score = evaluate(target, predicted_data, \"mae\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc56360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = data.drop(\"prix_m2\", axis = 1)\n",
    "\n",
    "training_data, test_data = train_test_split(data, test_size = 0.2)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60172ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes retenues pour la modélisation\n",
    "\n",
    "features_name = ['valeur_fonciere', 'type_local', 'surface_reelle_bati', 'nombre_pieces_principales', \n",
    "                 'nature_culture', 'surface_terrain', 'longitude', 'latitude', 'code_departement', 'prix_m2']\n",
    "max_depth = 7\n",
    "\n",
    "model_ensae, params_ensae = train_model(training_data, max_depth, features_name)\n",
    "\n",
    "score = backtest_model(test_data, model_ensae, features_name)\n",
    "\n",
    "print(f\"Le score SMAPE avec les features sélectionnés est : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y = data[\"valeur_fonciere\"].values\n",
    "\n",
    "X = data.drop([\"valeur_fonciere\", \"prix_m2\"], axis = 1).values\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 30, min_samples_split = 5)\n",
    "\n",
    "model.fit(X,y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d1185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2de820c",
   "metadata": {},
   "source": [
    "**2 - Eloi Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les fichiers sont renommés valeursfoncieres-(année)\n",
    "\n",
    "def preprocessing(year):\n",
    "    # path = 'Users\\victo\\Desktop\\ENSAE\\Python\\tokenisation-immo\\valeursfoncieres-'+str(year)+'.csv'\n",
    "    table = pd.read_csv('data/valeursfoncieres-'+ str(year) +'.csv', sep = ',')\n",
    "    \n",
    "    a = [2, 4, 5, 6, 7, 8, 9, 10, 12, 29, 31, 32, 38, 39, 40] \n",
    "    # vecteur des n° des colonnes qui nous intéressent\n",
    "    \n",
    "    a = [k - 1 for k in a]\n",
    "    \n",
    "    table = table[table.columns[a]]\n",
    "\n",
    "    ventes_types = list(table[table.columns[1]].unique())\n",
    "    \n",
    "    table = table[(table['nature_mutation'] == 'Vente') | \n",
    "                  (table['nature_mutation'] == \"Vente en l'état futur d'achèvement\")]\n",
    "\n",
    "    table = table[(table['nombre_lots'] == 0) | (table['nombre_lots'] == 1)]\n",
    "\n",
    "    table = table[table['surface_reelle_bati']!=0]\n",
    "\n",
    "    table = table[table['surface_reelle_bati'].notna()]\n",
    "\n",
    "    table = table[table['valeur_fonciere'].notna()]\n",
    "    \n",
    "    table['adresse_numero'] = table['adresse_numero'].fillna('0').astype(int)\n",
    "    table['adresse_suffixe'] = table['adresse_suffixe'].fillna(' ')\n",
    "    table['adresse_code_voie'] = table['adresse_code_voie'].fillna(' ')\n",
    "    table['adresse_nom_voie'] = table['adresse_nom_voie'].fillna(' ')\n",
    "    table['code_postal'] = table['code_postal'].fillna('0').astype(int)\n",
    "    table['nom_commune'] = table['nom_commune'].fillna(' ')\n",
    "\n",
    "    table['Adresse'] = table['adresse_numero'].astype(str) + ' ' + table['adresse_suffixe'] + ' ' + table['adresse_code_voie'] + ' ' + table['adresse_nom_voie'] + ' ' + table['nom_commune'] + ' ' + table['code_postal'].astype(str) + ' ' + 'France'    \n",
    "    \n",
    "    table.reset_index(drop = True, inplace = True)\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessing(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e29e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop_duplicates(subset = ['date_mutation', 'valeur_fonciere', 'adresse_nom_voie'], keep='last')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour mettre dans 'dicte' les 4 csv après preprocessing\n",
    "\n",
    "dicte = {}\n",
    "years = [2017,2018,2019,2020]\n",
    "for k in years:\n",
    "    dicte[k-2017] = preprocessing(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "for k in range(4):\n",
    "    output = pd.concat((output,dicte[k]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[['date_mutation', 'nature_mutation', 'valeur_fonciere', 'type_local', \n",
    "                 'surface_reelle_bati', 'surface_terrain', 'Adresse', 'latitude', 'longitude']]\n",
    "output.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89351c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour exporter le final en div=10 petits fichiers\n",
    "\n",
    "div=10\n",
    "for k in range(div):\n",
    "    name='final-'+str(1+k)+'.csv'\n",
    "    df=output[k*round(len(output)/div):(k+1)*round(len(output)/div)]\n",
    "    df.to_csv(name,index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585a6dd",
   "metadata": {},
   "source": [
    "**2-1 création du modèle pour obtenir le prix moyen du voisinage (BallTree)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb0eae",
   "metadata": {},
   "source": [
    "**2.1.1 Importation des données**\n",
    "\n",
    "data_vf : base de données de l'INSEE sur l'historique des valeurs foncières\n",
    "\n",
    "data_communes : base de données de l'INSEE sur les communes françaises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation de data_vf\n",
    "div = 10\n",
    "data_vf = pd.read_csv('data/final-1.csv', sep = ',')\n",
    "for k in range(1, div):\n",
    "    name = 'data/final-' + str(1 + k) + '.csv'\n",
    "    data_vf = pd.concat([data_vf, pd.read_csv(name, sep = ',')])\n",
    "    \n",
    "# importation de data_communes\n",
    "data_communes = pd.read_csv('communes_insee.csv', sep = ';')\n",
    "\n",
    "# importation de data_regions\n",
    "data_regions = pd.read_csv('communes-departement-region.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086d2d5",
   "metadata": {},
   "source": [
    "**2.1.2 Visualisation du dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25365b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de data_vf\n",
    "print(\"Nombre de lignes de data data_vf :\")\n",
    "print(len(data_vf))\n",
    "print(\"Nombre de colonnes de data data_vf :\")\n",
    "print(len(data_vf.columns))\n",
    "print(\"Visualisation de data_vf :\")\n",
    "data_vf.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee25c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de data_communes\n",
    "print(\"Nombre de lignes de data data_communes :\")\n",
    "print(len(data_communes))\n",
    "print(\"Nombre de colonnes de data data_communes :\")\n",
    "print(len(data_communes.columns))\n",
    "print(\"Visualisation de data_communes :\")\n",
    "data_communes[\"REG\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de data_regions\n",
    "print(\"Nombre de lignes de data data_regions :\")\n",
    "print(len(data_regions))\n",
    "print(\"Nombre de colonnes de data data_regions :\")\n",
    "print(len(data_regions.columns))\n",
    "print(\"Visualisation de data_regions :\")\n",
    "display(data_regions.sample(3))\n",
    "len(data_regions[\"code_region\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aec367",
   "metadata": {},
   "source": [
    "**2.1.3 Création d'une BD inédite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ab83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = pd.read_csv(\"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\")\n",
    "df_co2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331069fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vf[data_vf.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb21a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_vf.copy()\n",
    "data_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# prix_m2\n",
    "data_new['prix_m2'] = data_vf['surface_terrain'] / data_vf['valeur_fonciere']\n",
    "\n",
    "# cp\n",
    "data_new['cp'] = [x[-12:][:5] for x in data_vf[\"Adresse\"].values]\n",
    "# data_new.set_index('cp')\n",
    "\n",
    "# dep\n",
    "data_new['dep'] = [x[:2] for x in data_new['cp'].values]\n",
    "\n",
    "# region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c951e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_region\n",
    "x = data_new[\"cp\"].loc[2]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7328f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regions[\"nom_region\"].iloc[data_new[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = 13\n",
    "appart_old[‘Distance moyenne’]=np.zeros(len(appart_old))\n",
    "appart_old[‘Indices voisins’]=np.zeros(len(appart_old))\n",
    "models={}\n",
    "regions=appart_old.Région.unique()\n",
    "for k in range(len(regions)):\n",
    "    name=’appart_’+regions[k]\n",
    "    data=appart_old[appart_old.Région==regions[k]]\n",
    "    data=data.reset_index(drop=True)\n",
    "    models[k]=BallTree(data[[‘latitude_r’, ‘longitude_r’]].values, leaf_size=2, metric=’haversine’)\n",
    "    save_obj(models[k], name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
