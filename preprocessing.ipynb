{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8296a2-130c-412f-b470-49c5ae1532b4",
   "metadata": {},
   "source": [
    "# Etape 1 : preprocessing DVF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c80171-df05-43a6-b027-1ebabfd7a1a6",
   "metadata": {},
   "source": [
    "### 1.1. Importation du dataset DVF :\n",
    "\n",
    "Nous importons le dataset « **Demandes de valeurs foncières** » (DVF), publié par la DGFiP, permet de connaître les transactions immobilières intervenues au cours des cinq dernières années sur le territoire métropolitain et les DOM-TOM, à l’exception de l’Alsace, de la Moselle et de Mayotte. Les données contenues sont issues des actes notariés et des informations cadastrales.\n",
    "\n",
    "Fichiers 2017-2020 : https://files.data.gouv.fr/geo-dvf/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf301ebd-3b13-4f6e-b1f0-7f743874aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2021/full.csv.gz\"\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv(name, sep = ',')\n",
    "    \"\"\"\n",
    "    for year in range(2017, 2021):\n",
    "        name = \"https://files.data.gouv.fr/geo-dvf/latest/csv/\" + str(year) + \"/full.csv.gz\"\n",
    "        table = pd.concat([table, pd.read_csv(name, sep = ',')])\n",
    "\n",
    "    display(\"Taille de table :\")\n",
    "    display(table.shape)\n",
    "    table.head()\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "table = load_data()\n",
    "\n",
    "# On ne travaille que sur les données du S1 2021, afin d'avoir des calculs moins coûteux en temps.\n",
    "# Les transactions du S1 2021 représentent tout de même un dataset de 1 200 000 lignes...\n",
    "# Pour travailler sur l'ensemble des données (2017-2021), il suffit d'enlever les guillemets ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f9f02-ad7c-4214-9690-57750c6e8481",
   "metadata": {},
   "source": [
    "### 1.2. Visualisation des données DVF\n",
    "\n",
    "Il s'agit dans cette section de se faire **des premières intuitions sur les données**. \n",
    "\n",
    "En particulier, on se rend compte d'un **problème de preprocessing** : une transaction peut correspondre à plusieurs lignes avec la même valeur foncière sur chaque ligne. Autrement dit, **DVF affiche le même prix de vente global à chaque lot d'une même transaction**.\n",
    "\n",
    "Pour observer cela, nous allons créer **un identifiant de transaction unique**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49e2d4-1702-4306-b526-64439d54d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_id(table):\n",
    "\n",
    "    # Création d'une adresse générique\n",
    "    table['adresse_numero'] = table['adresse_numero'].fillna('0').astype(int)\n",
    "    table['adresse_suffixe'] = table['adresse_suffixe'].fillna(' ')\n",
    "    table['adresse_code_voie'] = table['adresse_code_voie'].fillna(' ')\n",
    "    table['adresse_nom_voie'] = table['adresse_nom_voie'].fillna(' ')\n",
    "    table['code_postal'] = table['code_postal'].fillna('0').astype(int)\n",
    "    table['nom_commune'] = table['nom_commune'].fillna(' ')\n",
    "\n",
    "    # Ajout de \"\\\" pour que l'opération soit visible à l'écran en entier\n",
    "    table[\"adresse\"] = table['adresse_numero'].astype(str) + ' ' + table['adresse_suffixe'] + ' ' + \\\n",
    "                    table['adresse_code_voie'] + ' ' + table['adresse_nom_voie'] + ' ' + table['nom_commune'] + ' ' + \\\n",
    "                    table['code_postal'].astype(str) + ' ' + 'France'\n",
    "\n",
    "    # Création d'un identifiant de transaction :\n",
    "    # Pour identifier les doublons, l'adresse ne suffit pas : un bien peut avoir été vendu deux fois dans la même année\n",
    "    table[\"identifiant_transaction\"] = table[\"adresse\"].astype(str) + ' le ' + table[\"date_mutation\"].astype(str)\n",
    "    \n",
    "    return table\n",
    "\n",
    "table = sales_id(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b7e85-f328-4edd-919a-a8216d01cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problème dans les données et vérification de la validité de l'identifiant de transaction :\n",
    "\n",
    "# display(table[\"identifiant_transaction\"].loc[0])\n",
    "# display(table[\"identifiant_transaction\"].loc[1])\n",
    "# display(\"Si l'identifiant de transaction est valide, alors True doit s'afficher :\")\n",
    "# table[\"identifiant_transaction\"].loc[0] == table[\"identifiant_transaction\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8016e7-e85b-4487-bdc9-98f7b3fafa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On constate, encore une fois, le problème relevé ci-dessus :\n",
    "\n",
    "# display(\"Nombre d'adresses uniques dans le DataFrame :\")\n",
    "# display(len(table[\"adresse\"].unique()))\n",
    "\n",
    "# display(\"Nombre d'identifiant_transaction uniques dans le DataFrame :\")\n",
    "# display(len(table[\"identifiant_transaction\"].unique()))\n",
    "\n",
    "# display(\"Nombre de lignes dans le DataFrame :\")\n",
    "# display(len(table))\n",
    "\n",
    "# display(\"Nombre moyen de lignes par vente :\")\n",
    "# np.round(len(table) / len(table[\"identifiant_transaction\"].unique()), 2)\n",
    "\n",
    "# Une vente correspond à plusieurs lignes, les informations sont donc diffusées dans ces lignes..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97366e-94aa-42ae-9f33-2abc109442f5",
   "metadata": {},
   "source": [
    "Dès lors, si on entraîne l'algorithme de pricing sur ce dataset, il sera **biaisé** : \n",
    "* d'une part, il associerait à une dépendance de 20 m2 le prix d'un appartement de 200 m2\n",
    "* d'autre part, il ne prendrait pas en compte la plus-value apportée par un jardin à une maison, par une dépendance à un appartement, etc.\n",
    "\n",
    "Il conviendra donc de **retravailler les données pour obtenir une seule ligne par transaction**.\n",
    "\n",
    "**Le notebook \"cleaning-dvf\"** (lien : https://github.com/victor-kerros/tokenisation-immo/blob/main/cleaning-dvf.ipynb) revient en détail sur ce problème de preprocessing et effectue ce travail de nettoyage. Dans la mesure où cette solution de nettoyage est très coûteuse en temps, nous privilégions **une solution plus efficace** dans le cadre de ce projet : nous ne retenons que les transactions ne faisant l'objet que d'une seule ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e04503-143b-4e58-aac1-90674fe54cbe",
   "metadata": {},
   "source": [
    "### 1.3. Création du dataset final DVF\n",
    "\n",
    "D'abord, nous ne prenons que les colonnes suivantes :\n",
    "- Date de vente/mutation\n",
    "- Nature mutation (pour séparer les ventes en VEFA et les ventes classiques)\n",
    "- Valeur foncière (prix de vente)\n",
    "- Colonnes liées à l’adresse (pour nous permettre de localiser le bien)\n",
    "- Adresse\n",
    "- Code Postal\n",
    "- Type local (maison/appartement/Local commercial/Dépendance etc)\n",
    "- Surface réelle bâtie (nb de mètre carré du bien bâti)\n",
    "- Surface terrain (nb de mètre carré du terrain associé au bien)\n",
    "\n",
    "Ensuite, comme annoncé, **nous ne retenons que les transactions ne faisant l'objet que d'une seule ligne pour créer \"data\"** : le dataset final avec lequel nous allons travailler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563c9574-71e1-4cd7-a4ea-e732de2bf17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_734/3927942465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'surface_reelle_bati'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nombre_pieces_principales'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nature_culture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surface_terrain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'longitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             'latitude', 'adresse', 'code_departement', 'identifiant_transaction']\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtable_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolonnes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# On agrège les types de cultures différents de NaN, sols, terrain à bâtir et  : on les renomme \"culture\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "def create_data_vf(table):\n",
    "\n",
    "    # On crée le dataframe table_vf avec les seules colonnes qui nous intéressent\n",
    "    colonnes = [\"date_mutation\", \"nature_mutation\", \"valeur_fonciere\", \"code_postal\", 'type_local',\n",
    "                'surface_reelle_bati', 'nombre_pieces_principales', 'nature_culture', 'surface_terrain', 'longitude', \n",
    "                'latitude', 'adresse', 'code_departement', 'identifiant_transaction']\n",
    "    table_vf = table[colonnes].copy()\n",
    "\n",
    "    # On agrège les types de cultures différents de NaN, sols, terrain à bâtir et  : on les renomme \"culture\"\n",
    "    culture_type = ['taillis simples', 'eaux', 'landes', 'taillis sous futaie', 'prés', 'terres', 'peupleraies', \n",
    "                    'vignes', 'bois', 'vergers', 'carrières', 'futaies résineuses', 'pâtures', 'futaies feuillues', \n",
    "                    'futaies mixtes', 'chemin de fer', 'oseraies', 'pacages', 'prés plantes', 'terres plantées', \n",
    "                    'landes boisées', 'herbages', \"prés d'embouche\"]\n",
    "\n",
    "    for x in culture_type:\n",
    "        table_vf.loc[table_vf[\"nature_culture\"] == x, \"nature_culture\"] = \"culture\"\n",
    "\n",
    "    # On ne retient que les transactions ayant fait l'objet d'une seule et unique ligne\n",
    "    table_vf_dup = table_vf.copy()\n",
    "    table_vf_uni = table_vf.copy()\n",
    "\n",
    "    # On récupère les indices des transactions dupliquées...\n",
    "    # i.e. les lignes où on retrouve un id de transaction utilisé ailleurs\n",
    "    dup_id = table_vf_dup.groupby('identifiant_transaction').size()\n",
    "    dup_id = dup_id[dup_id > 1]\n",
    "    dup_id = dup_id.reset_index()\n",
    "\n",
    "    table_vf_dup = table_vf_dup[table_vf_dup['identifiant_transaction'].isin(dup_id[\"identifiant_transaction\"])]\n",
    "    table_vf_uni = table_vf_uni[~table_vf_uni['identifiant_transaction'].isin(dup_id[\"identifiant_transaction\"])]\n",
    "\n",
    "    # Décommenter les lignes ci-dessous pour obtenir le nombre de transactions non dupliquées\n",
    "    # print(\"Taille de table_vf_uni (nombre de transactions non dupliquées) :\")\n",
    "    # print(table_vf_uni.shape)\n",
    "\n",
    "    # La solution la plus efficace, pour éviter un nettoyage trop coûteux en temps...\n",
    "    # est de ne retenir que les transactions non dupliquées.\n",
    "    data = table_vf_uni\n",
    "    data = data.reset_index().drop(\"index\", axis = 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = create_data_vf(table)\n",
    "\n",
    "# Visualisation de data (trois premières lignes) :\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c86018-de66-4ffb-8852-bc841944405a",
   "metadata": {},
   "source": [
    "### 1.4. Valeurs extrêmes dans le dataset DVF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c25d66-a7a5-455b-b7c4-4c235772eb61",
   "metadata": {},
   "source": [
    "On s'intéresse aux **valeurs extrêmes dans le dataset**. En effet, afin d'avoir un entraînement fiable, nous devons les enlever (sinon, il y aura trop de bruit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3d5ec-5658-40b9-b6bc-fe80c2925358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_display(data):\n",
    "\n",
    "    fig, axs = plt.subplots(1,4)\n",
    "    fig.suptitle(\"Boxplot des variables d'intérêt :\")\n",
    "\n",
    "    axs[0].boxplot(data[data['valeur_fonciere'].notna()]['valeur_fonciere'])\n",
    "    axs[0].set(title = \"Valeurs foncières\")\n",
    "\n",
    "    axs[1].boxplot(data[data['surface_reelle_bati'].notna()]['surface_reelle_bati'])\n",
    "    axs[1].set(title = \"Surface bati\")\n",
    "\n",
    "    axs[2].boxplot(data[data['nombre_pieces_principales'].notna()]['nombre_pieces_principales'])\n",
    "    axs[2].set(title = \"Nbre pièces\")\n",
    "\n",
    "    axs[3].boxplot(data[data['surface_terrain'].notna()]['surface_terrain'])\n",
    "    axs[3].set(title = \"Surface terrain\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae50f18-42d4-4270-87ef-1302cedb9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot_display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59a9bf-e9ed-4076-82e0-5a7aed1cd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.boxplot(x = \"valeur_fonciere\", y = \"type_local\", data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed9103-5358-4b3c-a0ca-671f2b976e6a",
   "metadata": {},
   "source": [
    "On constate sur ces boxplots que le dataset présente des valeurs extrêmes **particulièrement hautes** dans les quatre variables d'intérêt. \n",
    "\n",
    "En particulier, les locaux industriels, commerciaux et assimilés ont des valeurs extrêmes très importantes.\n",
    "\n",
    "On observe également des valeurs extrêmes **particulièrement basses**, comme le montrent les cellules ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852d9c7-fdaf-41d1-b0df-5386329e247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(data[\"valeur_fonciere\"]))\n",
    "valeurs = [1.0, 10.0, 1000.0, 5000.0, 10000.0]\n",
    "for i in valeurs:\n",
    "    display(\"Le nombre de valeurs foncières inférieures ou égales à \"+str(i)+\" est de:\")\n",
    "    display(sum(data[\"valeur_fonciere\"] <= i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8cbae-9c55-4582-a1b2-ab4f63fee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(data[\"surface_reelle_bati\"]))\n",
    "valeurs = [1.0, 5.0, 10.0, 30.0]\n",
    "for i in valeurs:\n",
    "    display(\"Le nombre de surfaces bati intérieures ou égales à \"+str(i)+\" est de:\")\n",
    "    display(sum(data[\"surface_reelle_bati\"] <= i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55591d-7da5-4649-ba84-0b3b2cd86ae6",
   "metadata": {},
   "source": [
    "On constate que bien qu'il n'y ait pas de valeurs foncières nulle, il y en a **de nombreuses qui sont inférieures ou égales à 10**.\n",
    "On considère qu'**une transaction est crédible lorsque la valeur foncière est supérieure à 5000** (en-dessous, il s'agit d'une vente qui ne nous intéresse pas).\n",
    "\n",
    "De même, on considère qu'**une transaction est crédible lorsque la surface du bâtiment est supérieure à 10 m2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366f434-5e21-4b13-b06d-a600e0344ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'abord, on écarte les valeurs foncières inférieures à 5000 et les surface_reelle_bati inférieures à 10 m2\n",
    "\n",
    "data = data[data[\"valeur_fonciere\"] > 4999]\n",
    "\n",
    "data = data[data[\"surface_reelle_bati\"] > 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9924ff-2ccc-42c4-82f1-0eea77e8fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il n'y a plus de Dépendances dans le dataset...\n",
    "\n",
    "# display(data[\"type_local\"].unique())\n",
    "# data.drop([\"code_postal\", \"longitude\", \"latitude\"], axis = 1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f8a95-b609-49d6-bf3c-24042e006a9d",
   "metadata": {},
   "source": [
    "Par ailleurs, on observe avec le describe ci-dessus que **les écart-types sont très importants par rapport aux moyennes**, surtout pour les variables \"valeur_fonciere\", \"surface_reelle_bati\" et \"surface_terrain\".\n",
    "Donc, **on enlève les valeurs trop hautes** : ici, cela consiste à *enlever les valeurs dont l'écart à la moyenne en valeur absolue est supérieure à 4 fois l'écart-type*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d5b57-c210-45f6-ad40-cdc9ad41cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(data):\n",
    "    \n",
    "    # Pour valeur_fonciere :\n",
    "    data = data[~(np.abs(data['valeur_fonciere'] - data['valeur_fonciere'].mean()) > (4 * data['valeur_fonciere'].std()))]\n",
    "\n",
    "    # Pour surface_reelle_bati :\n",
    "    data = data[~(np.abs(data['surface_reelle_bati'] - data['surface_reelle_bati'].mean()) > (4 * data['surface_reelle_bati'].std()))]\n",
    "\n",
    "    # Pour surface_terrain :\n",
    "    data = data[~(np.abs(data['surface_terrain'] - data['surface_terrain'].mean()) > (4 * data['surface_terrain'].std()))]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = clean_outliers(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abf057-44dc-4d81-b77e-629237ef6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.drop([\"code_postal\", \"longitude\", \"latitude\"], axis = 1).describe())\n",
    "boxplot_display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259bdbe3-075c-429f-837e-5989e5e309fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"valeur_fonciere\", y = \"type_local\", data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cde49-f7c0-46af-a1cb-9ddef6d9aa8e",
   "metadata": {},
   "source": [
    "**Ces boxplots correspondent davantage avec la réalité** (médiane des ventes autour de 150 000 euros)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
